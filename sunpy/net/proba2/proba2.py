import requests

import astropy.table

from sunpy.net import attrs as a
from sunpy.net.base_client import BaseClient, QueryResponseTable, convert_row_to_table


class Proba2Response(QueryResponseTable):
    query_args = astropy.table.TableAttribute()
    requests = astropy.table.TableAttribute()
    display_keys = ['calibrated', 'extension', 'file_date', 'file_name', 'file_oid', 'file_path', 'file_size', 'file_type', 'instrument_name', 'instrument_oid', 'processing_level']
    # This variable is used to detect if the result has been sliced before it is passed
    # to fetch and issue a warning to the user about not being able to post-filter JSOC searches.
    _original_num_rows = astropy.table.TableAttribute(default=None)

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self._original_num_rows = len(self)


class Proba2Client(BaseClient):
    """
    Provides access to the Proba-2 in-situ DSLP data.

    The HEK stores solar feature and event data generated by algorithms and
    human observers.
    will insert description here
    """

    @classmethod
    def _can_handle_query(cls, *query):
        required = {a.Time}
        optional = {a.proba2.ProcessingLevel, a.Instrument}
        return cls.check_attr_types_in_query(query, required, optional)

    @classmethod
    def _attrs_module(cls):
        return 'proba2', 'sunpy.net.proba2.attrs'

    def search(self, *args, **kwargs):
        response = Proba2Response(client=self)
        qrdict = {}
        for elem in args:
            if isinstance(elem, a.Time):
                qrdict['Time'] = elem
            else:
                raise ValueError(
                    f"{elem.__class__.__name__} should be a ``attrs.Time`` attribute.")
        qrdict.update(kwargs)
        start_time = qrdict['Time'].start.isot.replace('T', ' ')[:-4]
        end_time = qrdict['Time'].end.isot.replace('T', ' ')[:-4]
        results = self.makequery(start_time=start_time, end_time=end_time)
        return results

    def makequery(self, start_time, end_time):
        s = f"SELECT * FROM p2sa.v_file WHERE (file_date >= '{start_time}') AND (file_date <= '{end_time}') AND (instrument_name in ('DSLP')) ORDER BY file_date ASC"
        print("s is:", s)
        print("url is:", f"http://p2sa.esac.esa.int/p2sa-sl-tap/tap/sync?REQUEST=doQuery&LANG=ADQL&FORMAT=JSON&PHASE=RUN&QUERY={s}")
        response = requests.get(f"http://p2sa.esac.esa.int/p2sa-sl-tap/tap/sync?REQUEST=doQuery&LANG=ADQL&FORMAT=JSON&PHASE=RUN&QUERY={s}")
        response = response.json()
        names = [field['name'] for field in response['metadata']]
        response_table = QueryResponseTable(rows=response['data'], names=names)
        return response_table

    @convert_row_to_table
    def fetch(self, query_results, *, path=None, downloader, **kwargs):
        for row in query_results:
            filename = row['file_name']
            filepath = path.format(file=filename,  **row.response_block_map)
            url = f"http://p2sa.esac.esa.int/"+row['file_path'].replace('\\', '')+'/'+filename
            print(url, filename)
            downloader.enqueue_file(url, filepath)
            res = downloader.download()
            return res
